<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Social meta: fill accurately--this is your business card on the web -->
  <meta name="description" content="Story2Board is a training‑free framework for generating expressive, coherent multi‑panel storyboards from text while preserving character identity and layout diversity.">
  <meta property="og:title" content="Story2Board: A Training-Free Approach for Expressive Storyboard Generation"/>
  <meta property="og:description" content="Training‑free storyboard generation with character consistency and dynamic layouts."/>
  <meta property="og:url" content="https://daviddinkevich.github.io/Story2Board/"/>
  <!-- 1200×630 recommended -->
  <meta property="og:image" content="static/images/teaser.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Story2Board: A Training-Free Approach for Expressive Storyboard Generation">
  <meta name="twitter:description" content="Training‑free storyboard generation with character consistency and dynamic layouts.">
  <!-- 1200×600 recommended -->
  <meta name="twitter:image" content="static/images/teaser.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- SEO keywords -->
  <meta name="keywords" content="Story2Board, storyboard generation, diffusion, mutual attention, latent panel anchoring, reciprocal attention value mixing, visual world models, generative models, computer vision, video, DiT, Stable Diffusion 3, Flux">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Story2Board</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <!-- =========================== -->
  <!--        HERO + AUTHORS       -->
  <!-- =========================== -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Story2Board: A Training‑Free Approach for Expressive Storyboard Generation</h1>

            <!-- Authors with linked names and affiliations -->
            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://daviddinkevich.github.io" target="_blank" rel="noopener">David Dinkevich</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://levymsn.github.io/" target="_blank" rel="noopener">Matan Levy</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://omriavrahami.com/" target="_blank" rel="noopener">Omri Avrahami</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://chechiklab.biu.ac.il/~dvirsamuel/" target="_blank" rel="noopener">Dvir Samuel</a><sup>2,3</sup>,</span>
              <span class="author-block"><a href="https://www.cs.huji.ac.il/~danix/" target="_blank" rel="noopener">Dani Lischinski</a><sup>1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup>Hebrew University of Jerusalem, Israel<br>
                <sup>2</sup>OriginAI, Israel<br>
                <sup>3</sup>Bar-Ilan University, Israel
              </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Paper (disable or link later) -->
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark" aria-disabled="true">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>PDF (coming soon)</span>
                  </a>
                </span>
     
                <!-- Supplementary (optional) -->
<!--                 <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark" aria-disabled="true">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Supplementary (coming soon)</span>
                  </a>
                </span>
 -->
                <!-- ArXiv abstract Link (coming soon) -->
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark" aria-disabled="true">
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>arXiv (coming soon)</span>
                  </a>
                </span>

                <!-- Github link (code to be released later) -->
                <span class="link-block">
                  <a href="https://github.com/daviddinkevich/Story2Board" target="_blank" class="external-link button is-normal is-rounded is-dark" aria-disabled="true">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code (coming soon)</span>
                  </a>
                </span>
                <!-- Benchmark link (to be released later) -->
                <span class="link-block">
                  <a href="https://github.com/daviddinkevich/Story2Board" target="_blank" class="external-link button is-normal is-rounded is-dark" aria-disabled="true">
                    <span class="icon"><i class="fas fa-database"></i></span>
                    <span>Benchmark (coming soon)</span>
                  </a>
                </span>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- =========================== -->
  <!--            TEASER           -->
  <!-- =========================== -->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
<!--         <img src="static/images/teaser_stacked_2.png" alt="Story2Board teaser" style="width: 100%; height: auto;" /> -->
      <img src="static/images/teaser-2400.webp" alt="Story2Board teaser" style="width: 100%; height: auto;"/>

        <h2 class="subtitle has-text-centered">
          <span style="font-variant: small-caps;">Story2Board</span>: 
          Training-free storyboard generation that balances identity consistency with cinematic layout diversity.
        </h2>
      </div>
    </div>
  </section>

  <!-- =========================== -->
  <!--           ABSTRACT          -->
  <!-- =========================== -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We present <em>Story2Board</em>, a training‑free framework for expressive storyboard generation from natural language. Existing methods narrowly focus on subject identity, overlooking key aspects of visual storytelling such as spatial composition, background evolution, and narrative pacing. To address this, we introduce a lightweight consistency framework composed of two components: <em>Latent Panel Anchoring</em>, which preserves a shared character reference across panels, and <em>Reciprocal Attention Value Mixing</em>, which softly blends visual features between token pairs with strong reciprocal attention. Together, these mechanisms enhance coherence without architectural changes or fine‑tuning, enabling state‑of‑the‑art diffusion models to generate visually diverse yet consistent storyboards. To structure generation, we use an off‑the‑shelf language model to convert free‑form stories into grounded panel‑level prompts. To evaluate, we propose the <em>Rich Storyboard Benchmark</em> and a <em>Scene Diversity</em> metric that quantify layout variation and background‑grounded storytelling, in addition to consistency.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- =========================== -->
  <!--           METHOD            -->
  <!-- =========================== -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-10">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">
          <p>
            Our goal is to represent a narrative as a coherent sequence of storyboard panels --
            each depicting a different scene while preserving the identity and appearance of
            the main character(s). To achieve this, we generate all panels in a batch, with one
            <em>reference panel</em> that serves as a shared visual reference. During generation,
            we maintain consistency by replacing the reference region of each latent with the
            corresponding region from the batch’s reference panel, and we apply
            <strong>Reciprocal Attention Value Mixing (RAVM)</strong> to blend the reference’s
            features into the target panels’ self-attention layers. This combination
            enforces identity consistency while allowing each panel to retain its own
            scene layout and composition.
          </p>
          </div>
          <!-- Placeholder: Overview figure -->
          <figure style="margin:18px 0">
            <img src="static/images/overview_figure.png" alt="Method overview: LLM Director, LPA co‑denoising, and decoding."/>
            <figcaption class="has-text-grey">
              <strong>Fig. 3.</strong> Our training-free storyboard generation pipeline.
              (1) <em>LLM Director</em>: Decomposes the story into a shared reference panel prompt and scene-level prompts.
              (2) <em>Co-denoising with LPA and RAVM</em>: Generates a batch of two-panel images, syncing the reference panel across the batch after each DiT block and blending features for consistency.
              (3) <em>Decode & crop</em>: Produces the final storyboard panels.
            </figcaption>
          </figure>

          <div class="content has-text-justified">
            <p>
              RAVM details. While an reference panel helps maintain overall identity consistency across scenes,
              it alone is not enough to capture fine-grained details. Subtle features--like the
              exact shape of a hand or the expression on a face--can still drift. Our
              <strong>Reciprocal Attention Value Mixing (RAVM)</strong> addresses this by
              identifying individual tokens in the reference and target panels that strongly
              attend to each other across the batch. We then blend their value representations
              in self-attention, ensuring that the most semantically aligned regions reinforce
              each other’s appearance.
            </p>
            <p>
              Unlike prior approaches that rely on coarse
              cross-attention maps to locate characters, RAVM operates directly at the token
              level, enabling a more precise and fine-grained blending scheme.
              Also, RAVM only modifies <em>value embeddings</em>, which affects appearance 
              without interfering with the scene layout generated by the model.
            </p>
          </div>
          <!-- Placeholder: RAVM figure -->
          <figure style="margin:18px 0">
            <img src="static/images/mutual_attention.png" alt="RAVM: mutual attention maps and value‑mixing between token pairs."/>
            <figcaption class="has-text-grey">
              <strong>Fig. 4.</strong> Visualization of <em>Reciprocal Attention Value Mixing (RAVM)</em> in action.
              <strong>Left:</strong> A generated two-panel output from our method, with the top panel serving as the shared reference.
              The red and green circles mark semantically corresponding character features (the hand) in the reference and target panels, respectively.
              <strong>Right:</strong> Heatmaps showing reciprocal attention scores at denoising step&nbsp;12 of&nbsp;28.
              <strong>Top-right:</strong> For each token in the top panel, we compute its reciprocal attention with the green-circled token in the bottom panel.
              <strong>Bottom-right:</strong> The reverse--each token in the bottom panel is scored based on reciprocal attention with the red-circled token in the top panel.
              In both cases, the hand token in the opposite panel receives the strongest reciprocal attention, showing that RAVM identifies semantically aligned token pairs for value mixing.
              This reinforces visual consistency without altering spatial composition.
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
  </section>

  <!-- =========================== -->
  <!--     QUALITATIVE RESULTS     -->
  <!-- =========================== -->
<!--   <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered">Qualitative Comparisons</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <img src="static/images/qualitative_eval.png" alt="Storyboard comparison grid 1"/>
            <h2 class="subtitle has-text-centered">
              Example storyboard generated with our method from a short fantasy narrative.  
              Our approach preserves the character’s identity and distinctive details across
              diverse scenes--from forest landscapes to glowing lakes--while allowing each
              panel to feature a unique cinematic composition. This balance between consistency
              and layout diversity enables richer visual storytelling than methods that fix the
              character’s pose or appearance too rigidly.
            </h2>
          </div>
          <div class="item">
            <img src="static/images/full_story.png" alt="Full story comparison"/>
            <h2 class="subtitle has-text-centered">Special capabilities: variable character count, multiple same‑type characters, and background‑level consistency.</h2>
          </div>
        </div>
      </div>
    </div>
  </section>
 -->
  <!-- =========================== -->
  <!--        MORE EXAMPLES        -->
  <!-- =========================== -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">More Results</h2>
        <div id="results-carousel-2" class="carousel results-carousel">
          
          <div class="item">
            <img src="static/images/carousel1.png" alt="Result 1" />
          </div>
  
          <div class="item">
            <img src="static/images/carousel2.png" alt="Result 2" />
          </div>
  
          <div class="item">
            <img src="static/images/carousel3.png" alt="Result 3" />
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- =========================== -->
  <!--     QUANTITATIVE RESULTS    -->
  <!-- =========================== -->
<!--   <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column column is-10">
          <h2 class="title is-3">Quantitative Results</h2>

          <figure style="margin:18px 0">
            <img src="static/images/quant_vqa_dreamsim.png" alt="Prompt alignment (VQAScore) vs. character consistency (DreamSim)."/>
            <figcaption class="has-text-grey">Prompt alignment (VQAScore) vs. character consistency (DreamSim). Our method dominates the Pareto front.</figcaption>
          </figure>

          <figure style="margin:18px 0">
            <img src="static/images/quant_diversity.png" alt="Scene diversity vs. character consistency."/>
            <figcaption class="has-text-grey">Scene diversity vs. character consistency. Strong identity preservation with rich layout variation.</figcaption>
          </figure>

          <figure style="margin:18px 0">
            <img src="static/images/length_scaling.png" alt="Prompt alignment vs. storyboard length."/>
            <figcaption class="has-text-grey">Prompt alignment vs. storyboard length. Our method remains stable for longer sequences.</figcaption>
          </figure>
        </div>
      </div>
    </div>
  </section> -->

  <!-- =========================== -->
  <!--            BIBTEX           -->
  <!-- =========================== -->
<!--   <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{dinkevich2025story2board,
  title   = {Story2Board: A Training-Free Approach for Expressive Storyboard Generation},
  author  = {Dinkevich, David and Levy, Matan and Avrahami, Omri and Samuel, Dvir and Lischinski, Dani},
  year    = {2025},
  journal = {Under review},
  note    = {arXiv: coming soon},
  url     = {https://daviddinkevich.github.io/Story2Board/}
}</code></pre>
    </div>
  </section>
 -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website; please link back to the template in the footer. <br>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
